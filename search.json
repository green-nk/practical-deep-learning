[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Practical Deep Learning",
    "section": "",
    "text": "This is knowledge repository for documenting what I have learned and projects I have done through the course. Besides, this part acts as a valuable guide to my way of learning things from the lecturer in Lesson 0 - Practical Deep Learning for Coders (fast.ai).",
    "crumbs": [
      "Practical Deep Learning"
    ]
  },
  {
    "objectID": "index.html#introduction",
    "href": "index.html#introduction",
    "title": "Practical Deep Learning",
    "section": "",
    "text": "This is knowledge repository for documenting what I have learned and projects I have done through the course. Besides, this part acts as a valuable guide to my way of learning things from the lecturer in Lesson 0 - Practical Deep Learning for Coders (fast.ai).",
    "crumbs": [
      "Practical Deep Learning"
    ]
  },
  {
    "objectID": "index.html#how-to-learn-deep-learning-like-a-skilled-practitioner",
    "href": "index.html#how-to-learn-deep-learning-like-a-skilled-practitioner",
    "title": "Practical Deep Learning",
    "section": "How to learn deep learning like a skilled practitioner?",
    "text": "How to learn deep learning like a skilled practitioner?\n\nBefore you want to deep dive into something, try it in a practical way. It will get you there faster.\n\nSo, this is an overview of how practitioner learns things.\n\n\n\n\n\nflowchart LR;\n    A[Passive Learning] --&gt; B[Active Learning - Experiment] --&gt; C[Active Learning - Quiz] --&gt; D[Active Learning - Project] --&gt; E[Active Learning - Sharing];\n\n\n\n\n\n\nYou will see that mostly 80% of the time is Active Learning!\nPassive learning can be watching lectures or reading articles/text books. But the key important here is you need to quickly get hands-on whatever you are learning after you understand at least 20% of the content.\nSo, the more specificed workflow to this course should look like this:\n\n\n\n\n\nflowchart LR;\n    A[Watch Lecture] --&gt; B[Run notebooks and Experiment] --&gt; C[Start from scratch] --&gt; D[Try with your own data] --&gt; E[Document and Sharing];\n\n\n\n\n\n\nFirst, by watching a lecture on Practical Deep Learning for Coders, we are going to understand the main concepts or jargons needed on the lesson.\nNext, we try it out! Doing an experiment on lecture notebooks and reading their documentation to gain more understanding. This will help strengthen your knowledge together with giving you hands-on experience.\nAfter that, start quizzing yourself, by clearing outputs first then running a notebook in Deep Learning for Coders with fastai & PyTorch Book from scratch. It’s an open-book quiz though so you can ask for help like browsing through a documentation or posting questions on the forum. Moreover, while you are running it, document some key ideas in the book apart from the lecture along the way.\nThen, apply your understanding with mini-project. Find interesting dataset first. The best places to start are Kaggle Datasets and Hugging Face Datasets. Doing this will help you gain even more experience and make sure you have done something related to your field, driving you to learn deeper.\nLast, document your work is very important. sharing is neccessary. You can do it in parallel while you studying passively and keep updating it throughout your learning. Doing these will help you retain information over time. They also assist in building your profile to the public — Showing others what you have done in the past through your work. These simple steps should get you started:\n\nDocumenting with Quarto. It is suitable for notebook documentation. Use Quarto Basic as a guide to start documenting.\nHosting your documentation as a website on GitHub Pages.\nSharing it on social media like Twitter or Linkedin.\n\n\n\n\n\n\n\nTip\n\n\n\nIt can be easy to get lost sometimes. Keep these 3 things in mind: Focus on your end-goal, Continue gaining your understanding in a bite-size by doing things and Be tenacious.",
    "crumbs": [
      "Practical Deep Learning"
    ]
  },
  {
    "objectID": "CHANGELOG.html",
    "href": "CHANGELOG.html",
    "title": "Changelog",
    "section": "",
    "text": "All notable changes to this project will be documented in this file.\n\n\n\n\n\n(quarto) Add sidebar navigation to the web\n(01-deep-learning-in-practice) Add examples of other tasks unrelated to images\n\n\n\n\n\n(01-deep-learning-in-practice) Fix error rendering mermaid by adding {} to guide a specific code block\n\n\n\n\n\n(01-deep-learning-in-practice) Run image classifier on Google Colab\n(quarto) Change mermaid theme to be more visible in dark theme\n\n\n\n\n\n(README) Add project description\n(index) Add lesson 0 as a homepage\n(index) Fix heading typo\n(01-pretrained-model) Add metadata reference for tables and figures\n(01-deep-learning-in-practice) Add introduction\n(01-deep-learning-in-practice) Add introduction to machine learning section\n(01-deep-learning-in-practice) Add questionaire and solution for chapter1\n(dl-in-practice) Update published date\n(horapa-vs-kaprao) Add introduction section\n(01-deep-learning-in-practice) Add open-in-colab link\n(horapa-vs-kaprao) Add open-in-colab link\n\n\n\n\n\n(horapa-vs-kaprao) Test run to collect the models\n\n\n\n\n\n(publish) Add github workflows"
  },
  {
    "objectID": "CHANGELOG.html#section",
    "href": "CHANGELOG.html#section",
    "title": "Changelog",
    "section": "",
    "text": "(quarto) Add sidebar navigation to the web\n(01-deep-learning-in-practice) Add examples of other tasks unrelated to images\n\n\n\n\n\n(01-deep-learning-in-practice) Fix error rendering mermaid by adding {} to guide a specific code block\n\n\n\n\n\n(01-deep-learning-in-practice) Run image classifier on Google Colab\n(quarto) Change mermaid theme to be more visible in dark theme\n\n\n\n\n\n(README) Add project description\n(index) Add lesson 0 as a homepage\n(index) Fix heading typo\n(01-pretrained-model) Add metadata reference for tables and figures\n(01-deep-learning-in-practice) Add introduction\n(01-deep-learning-in-practice) Add introduction to machine learning section\n(01-deep-learning-in-practice) Add questionaire and solution for chapter1\n(dl-in-practice) Update published date\n(horapa-vs-kaprao) Add introduction section\n(01-deep-learning-in-practice) Add open-in-colab link\n(horapa-vs-kaprao) Add open-in-colab link\n\n\n\n\n\n(horapa-vs-kaprao) Test run to collect the models\n\n\n\n\n\n(publish) Add github workflows"
  },
  {
    "objectID": "lectures/dl-in-practice/01-deep-learning-in-practice.html#setup",
    "href": "lectures/dl-in-practice/01-deep-learning-in-practice.html#setup",
    "title": "Whatelse to know to deep learning in practice?",
    "section": "Setup",
    "text": "Setup\nFirst, we need to setup an access to Google Drive. This is to persist data or artifacts in a local drive even when we are not connected to Google Colab.\n\nfrom google.colab import drive\ndrive.mount(\"/content/gdrive\")\n\nMounted at /content/gdrive\n\n\nThen, install ipywidgets and fastai as necessary dependencies and import them.\n\n!python -m pip install -Uqq ipywidgets fastai\n\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 139.4/139.4 kB 1.8 MB/s eta 0:00:00\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.3/2.3 MB 12.8 MB/s eta 0:00:00\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 16.3 MB/s eta 0:00:00\n\n\n\nfrom fastai.vision.all import *\nfrom fastai.text.all import *\nfrom fastai.tabular.all import *\nfrom fastai.collab import *",
    "crumbs": [
      "Lectures",
      "DL in practice",
      "Whatelse to know to deep learning in practice?"
    ]
  },
  {
    "objectID": "lectures/dl-in-practice/01-deep-learning-in-practice.html#introduction",
    "href": "lectures/dl-in-practice/01-deep-learning-in-practice.html#introduction",
    "title": "Whatelse to know to deep learning in practice?",
    "section": "Introduction",
    "text": "Introduction\n\nWhy Deep Learning?\nThis is a starting point to your deep learning journey. Before we dive into what you need to know about it and how, it is important to talk about Why?.\n\nIt is for everyone: One might say deep learning is like a blackbox. However, the truth is in practice, what you want to do is just to solve problem of your own interests and there are a lot of state-of-the-art models to help you do that.\nHuge amount of data: A lot of open-source and pre-trained model out there! So, there is no need for you to start collecting data from scratch just a few samples of it.\nHigh computational resources: You do not need to be Google or Microsoft to train such large models. Nowadays, everyone can access this kind of computational resouce for free.\nGood for thousands of use cases in different areas: There are remarkable accomplishment throughout the recent years that deep learning helps researchers and practitioners solve. Here is some of them:\n\nNatural language processing (NLP): answering questions; speech recognition; summarizing documents; classifying documents; translation;information retrieval (searching). Here is my recommendation on a comprehensive guide to NLP.\nComputer vision: image recognition; image captioning; image segmentation; image generation.\nRecommendation systems: product recommendations; web searching.\nGames: chess; go; real-time strategy games like StarCrafts.\nOthers: algoritmic trading; text-to-speech.\n\n\n\n\nNeural Networks: A Brief History\nThis is a simplified verison of ANNs history that you will help you contextualize on what we have been through and learn to not repeat some of it!\n\n\n\n\n\nflowchart LR;\n    A[Artificial Neurons] -- Unrecognized social position --&gt; B[Perceptrons] -- Failure to learn simple XOR --&gt; C[PDP] -- Approximation with one extra layer --&gt; D[Modern ANNs];\n\n\n\n\n\n\nBasically, what researchers have tried to do since 1943 is to develop a mathematical model of an artificial neuron inspired by the human brain. Although there are several years of misunderstanding of the theoretical issues, we still have multi-volume Parallel Distributed Processing (PDP) which acts as a backbone of modern ANNs. Here is the required components for this framework:\n\nA set of processing units\nA state of activation\nAn output function for each unit\nA pattern of connectivity among units\nA propagation rule for propagating patterns of activities through the network of connectivities\nAn activation rule for combining the inputs impinging on a unit with the current state of that unit to produce an output for the unit\nA learning rule whereby patterns of connectivity are modified by experience\nAn environment within which the system must operate\n\nAgain, thanks to the use of more layers, together with the improvement in hardware capability, the increase amount of data and algorithmic tweaks that allow neural networks to be trained faster and more easily, We now are able to complete complex tasks like an image recognizer by a only computer.\n\n\nCats and Dogs\nLet’s implement PDP framework in practice by using a pre-trained model to complete a task; an image recognizer perhaps. Here is what about to happen:\n\nA dataset called the Oxford-IIIT Pet Dataset that contains 7,349 images of cats and dogs from 37 different breeds will be downloaded from the fast.ai datasets collection to the GPU server you are using, and will then be extracted.\nA pretrained model that has already been trained on 1.3 million images, using a competition-winning model will be downloaded from the internet.\nThe pretrained model will be fine-tuned using the latest advances in transfer learning, to create a model that is specially customized for recognizing dogs and cats.\n\n\npath = untar_data(URLs.PETS)/'images'\n\nis_cat = lambda x: x[0].isupper()\ndls = ImageDataLoaders.from_name_func(\n    path, get_image_files(path), valid_pct=0.2, seed=42,\n    label_func=is_cat, item_tfms=Resize(224))\n\nlearn = vision_learner(dls, resnet34, metrics=error_rate)\nlearn.fine_tune(1)\n\n\n\n\n\n\n    \n      \n      100.00% [811712512/811706944 00:59&lt;00:00]\n    \n    \n\n\nDownloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n100%|██████████| 83.3M/83.3M [00:00&lt;00:00, 90.6MB/s]\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.163383\n0.030820\n0.012179\n00:48\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.055516\n0.037565\n0.012855\n01:00\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nDepending on your network speed, it might take a few minutes to download the pretrained model and dataset. Running fine_tune might take a minute or so. Often models in this book take a few minutes to train, as will your own models, so it’s a good idea to come up with good techniques to make the most of this time. For instance, keep reading the next section while training your model, or open up another notebook and use it for some coding experiments.\n\n\nAfter we have trained the model, we need to check if it can do something useful right? There are several ways we can do. The first way is to create an uploader for an interaction. This way is the simplest and suitable for users similiarized with GUI.\n\nfrom ipywidgets import FileUpload\n\n# This should prompt a uploader UI for file attachment\nuploader = FileUpload()\nuploader\n\n\n\n\nOr you can just past in a download link to download_image function provided by fastai library.\n\ndest = Path(\"gdrive/My Drive/practical-deep-learning/bin/\")\ndownload_images(dest, urls=[\"https://i.icanvas.com/COC490?d=3&sh=v&s=xl&p=1&bg=g&t=1648830566\"])\n\n\nimg = PILImage.create(\"/content/gdrive/MyDrive/practical-deep-learning/bin/75083824-ac57-46d2-acdb-2e0678aba62f.jpg\")\nimg.to_thumb(224)\n\n\n\n\n\n\n\n\n\nis_cat, _, probs = learn.predict(img)\n\nprint(f\"Is this a cat?: {is_cat}.\")\nprint(f\"Probability it's a cat: {probs[1]:.4f}\")\n\n\n\n\n\n\n\n\nIs this a cat?: False.\nProbability it's a cat: 0.0357\n\n\nAs you can see, the model can correctly classify even an image has some part that is not a dog! This is the power of a pre-trained model.\nBut what does it actually doing? we will have a look more closer into the code.\n\nHow Our Image Recognizer works\nLet’s look through the code first.\nuntar_data function has downloaded a standardard dataset from the fast.ai datasets collection (if not previously downloaded) to your server, extracts it (if not previously extracted), and returns a Path object with the extracted location:\npath = untar_data(URLs.PETS)/'images'\nNext, we define a function, is_cat, which labels cats based on a filename rule provided by the dataset creators:\nis_cat = lambda x: x[0].isupper()\nThen, we need to tell fastai what kind of dataset we have and how it is structured:\ndls = ImageDataLoaders.from_name_func(\n    path, get_image_files(path), valid_pct=0.2, seed=42,\n    label_func=is_cat, item_tfms=Resize(224))\nThere are various different classes for different kinds of deep learning datasets and problems—here we’re using ImageDataLoaders. The first part of the class name will generally be the type of data you have, such as image, or text.\nThe other important piece of information that we have to tell fastai is how to get the labels from the dataset. Computer vision datasets are normally structured in such a way that the label for an image is part of the filename, or path—most commonly the parent folder name. fastai comes with a number of standardized labeling methods, and ways to write your own. Here we’re telling fastai to use the is_cat function we just defined.\nFinally, we define the Transforms that we need. A Transform contains code that is applied automatically during training; fastai includes many predefined Transforms, and adding new ones is as simple as creating a Python function. There are two kinds: item_tfms are applied to each item (in this case, each item is resized to a 224-pixel square), while batch_tfms are applied to a batch of items at a time using the GPU, so they’re particularly fast!\nWhy 224 pixels? This is the standard size for historical reasons (old pretrained models require this size exactly), but you can pass pretty much anything. If you increase the size, you’ll often get a model with better results (since it will be able to focus on more details), but at the price of speed and memory consumption; the opposite is true if you decrease the size.\nThe Pet dataset contains 7,390 pictures of dogs and cats, consisting of 37 different breeds. Each image is labeled using its filename: for instance the file great_pyrenees_173.jpg is the 173rd example of an image of a Great Pyrenees breed dog in the dataset. The filenames start with an uppercase letter if the image is a cat, and a lowercase letter otherwise. We have to tell fastai how to get labels from the filenames, which we do by calling from_name_func (which means that labels can be extracted using a function applied to the filename), and passing is_cat, which returns x[0].isupper(), which evaluates to True if the first letter is uppercase (i.e., it’s a cat).\nThe most important parameter to mention here is valid_pct=0.2. This tells fastai to hold out 20% of the data and not use it for training the model at all. This 20% of the data is called the validation set; the remaining 80% is called the training set. The validation set is used to measure the accuracy of the model. By default, the 20% that is held out is selected randomly. The parameter seed=42 sets the random seed to the same value every time we run this code, which means we get the same validation set every time we run it—this way, if we change our model and retrain it, we know that any differences are due to the changes to the model, not due to having a different random validation set.\nNext, it tells `fastai to create a convolutional neural network (CNN) and specifies what architecture to use (i.e. what kind of model to create), what data we want to train it on, and what metric to use:\nlearn = vision_learner(dls, resnet34, metrics=error_rate)\nWhy a CNN? It’s the current state-of-the-art approach to creating computer vision models. Their structure is inspired by how the human vision system works.\nThere are many different architectures in fastai, which we will introduce in the later lecture (as well as discussing how to create your own). Most of the time, however, picking an architecture isn’t a very important part of the deep learning process. It’s something that academics love to talk about, but in practice it is unlikely to be something you need to spend much time on. There are some standard architectures that work most of the time, and in this case we’re using one called ResNet that we’ll be talking a lot about during the book; it is both fast and accurate for many datasets and problems. The 34 in resnet34 refers to the number of layers in this variant of the architecture (other options are 18, 50, 101, and 152). Models using architectures with more layers take longer to train, and are more prone to overfitting (i.e. you can’t train them for as many epochs before the accuracy on the validation set starts getting worse). On the other hand, when using more data, they can be quite a bit more accurate.\nWhat is a metric? A metric is a function that measures the quality of the model’s predictions using the validation set, and will be printed at the end of each epoch. In this case, we’re using error_rate, which is a function provided by fastai that does just what it says: tells you what percentage of images in the validation set are being classified incorrectly. Another common metric for classification is accuracy (which is just 1.0 - error_rate). There are many more to cover in the later lecture.\nThe concept of a metric may remind you of loss, but there is an important distinction. The entire purpose of loss is to define a “measure of performance” that the training system can use to update weights automatically. In other words, a good choice for loss is a choice that is easy for stochastic gradient descent to use. But a metric is defined for human consumption, so a good metric is one that is easy for you to understand, and that hews as closely as possible to what you want the model to do. At times, you might decide that the loss function is a suitable metric, but that is not necessarily the case.\nvision_learner also has a parameter pretrained, which defaults to True (so it’s used in this case, even though we haven’t specified it), which sets the weights in your model to values that have already been trained by experts to recognize a thousand different categories across 1.3 million photos (using the famous ImageNet dataset). A model that has weights that have already been trained on some other dataset is called a pretrained model. You should nearly always use a pretrained model, because it means that your model, before you’ve even shown it any of your data, is already very capable. And, as you’ll see, in a deep learning model many of these capabilities are things you’ll need, almost regardless of the details of your project. For instance, parts of pretrained models will handle edge, gradient, and color detection, which are needed for many tasks.\nWhen using a pretrained model, vision_learner will remove the last layer, since that is always specifically customized to the original training task (i.e. ImageNet dataset classification), and replace it with one or more new layers with randomized weights, of an appropriate size for the dataset you are working with. This last part of the model is known as the head.\nUsing pretrained models is the most important method we have to allow us to train more accurate models, more quickly, with less data, and less time and money. You might think that would mean that using pretrained models would be the most studied area in academic deep learning… but you’d be very, very wrong! The importance of pretrained models is generally not recognized or discussed in most courses, books, or software library features, and is rarely considered in academic papers.\nUsing a pretrained model for a task different to what it was originally trained for is known as transfer learning. Unfortunately, because transfer learning is so under-studied, few domains have pretrained models available. For instance, there are currently few pretrained models available in medicine, making transfer learning challenging to use in that domain. In addition, it is not yet well understood how to use transfer learning for tasks such as time series analysis.\n\n\n\n\n\n\nNote\n\n\n\nTransfer learning: using a pretrained model for a task different to what it was originally trained for.\n\n\nHere comes our training part. Our code tells fastai how to fit the model:\nlearn.fine_tune(1)\nAs we’ve discussed, the architecture only describes a template for a mathematical function; it doesn’t actually do anything until we provide values for the millions of parameters it contains.\nThis is the key to deep learning—determining how to fit the parameters of a model to get it to solve your problem. In order to fit a model, we have to provide at least one piece of information: how many times to look at each image (known as number of epochs). The number of epochs you select will largely depend on how much time you have available, and how long you find it takes in practice to fit your model. If you select a number that is too small, you can always train for more epochs later.\nBut why is the method called fine_tune, and not fit? fastai actually does have a method called fit, which does indeed fit a model (i.e. look at images in the training set multiple times, each time updating the parameters to make the predictions closer and closer to the target labels). But in this case, we’ve started with a pretrained model, and we don’t want to throw away all those capabilities that it already has. There are some important tricks that we are going to learn throughout the course to adapt a pretrained model for a new dataset — a process called fine-tuning.\n\n\n\n\n\n\nNote\n\n\n\nFine-tuning: a transfer learning technique where the parameters of a pretrained model are updated by training for additional epochs using a similar task and dataset.\n\n\nWhen you use the fine_tune method, fastai will use these tricks for you. There are a few parameters you can set (which we’ll discuss later), but in the default form shown here, it does two steps:\n\nUse one epoch to fit just those parts of the model necessary to get the new random head to work correctly with your dataset.\nUse the number of epochs requested when calling the method to fit the entire model, updating the weights of the later layers (especially the head) faster than the earlier layers (which, as we’ll see, generally don’t require many changes from the pretrained weights).\n\nThe head of a model is the part that is newly added to be specific to the new dataset. An epoch is one complete pass through the dataset. After calling fit, the results after each epoch are printed, showing the epoch number, the training and validation set losses (the “measure of performance” used for training the model), and any metrics you’ve requested (error rate, in this case).\n\n\nWhar Our Image Recognizer Learned\nBefore going to the next section, we have already know what our code has been doing. That’s good!\nBut intuition behind it, it also important for you as there is the key you can use to adapt this code to any kind of problems.\nIn 2013 a PhD student, Matt Zeiler, and his supervisor, Rob Fergus, published the paper “Visualizing and Understanding Convolutional Networks”, which showed how to visualize the neural network weights learned in each layer of a model. They carefully analyzed the model that won the 2012 ImageNet competition, and used this analysis to greatly improve the model, such that they were able to go on to win the 2013 competition!\nYou can see pictures of each layer in their paper. So, I am going to summarize here:\n\nAs the layer go deeper, the model learns more sophiticated features.\n\nThis statement provides an inspiration to what neural networks do in what so called the “blackbox”. Also, it is a confirmation that neural networks themselves have the ability to learn feature on theirown. This gives us a lot of potential:\n\nWe do not need hand-crafted features and preserve the nature of dataset.\nFlexibility on how to use the neural networks on every possible data format that you can imagine.",
    "crumbs": [
      "Lectures",
      "DL in practice",
      "Whatelse to know to deep learning in practice?"
    ]
  },
  {
    "objectID": "lectures/dl-in-practice/01-deep-learning-in-practice.html#what-is-machine-learning",
    "href": "lectures/dl-in-practice/01-deep-learning-in-practice.html#what-is-machine-learning",
    "title": "Whatelse to know to deep learning in practice?",
    "section": "What Is Machine Learning?",
    "text": "What Is Machine Learning?\nNow that we have learn deep learning through hands-on exercise, It is time to dig a lit bit deeper into it. We will start with Machine Learning.\nThis term is like a primitive to Deep Learning. What is means is that it is another paradiagm (as opposed to Traditional Programming) to get computers to complete a specific task. The key difference is here:\n\nML provides an ability for a computer to learn without explitcitly being programmed\n\nHere is an introduction to machine learning that I find easily to get started. This blog includes the main concepts and its real-world examples.\nNow, back to business, the basic of every traditional program should look like this:\n\n\n\n\n\nflowchart LR;\n    A([inputs]) --&gt; B[program] --&gt; C([results]);\n\n\n\n\n\n\nHowever, for tasks like image recognition. It is almost impossible for you as a programmer who write an instruction to turn inputs into results as we are human that can do it unconsciouly. Therefore, the new paradiagm to the problem comes in. Machine Learning seem like a good way to solve the problem but in reality how can we implement it.\nRemember PDP framework? we need various components for a computer to utilize in order to acheive our goal. The concepts like “weight assignment” and “performance evaluation” have emerged though it is crucial for a computer to do it automatically. So, we also need some mechanism to provide the ability to automate the process of improvement and make sure that the model can do whatever it is required to do. Here is the summary of what it should be look like:\n\n\n\n\n\nflowchart LR;\n    A([inputs]) --&gt; C[model];\n    B([weights]) --&gt; C[model];\n    C[model] --&gt; D([results]);\n    D([results]) --&gt; E([performance]);\n    E([performance]) -- update --&gt; B([weights]);\n\n\n\n\n\n\nSuch mechanism keep the model going toward perfection as it iteratively update weights. Also note that once the model is finished training, the weight themselves act as a part of the model.\nSo, the simplfied version of it would be something which quite similar to what traditional programming is:\n\n\n\n\n\nflowchart LR;\n    A([inputs]) --&gt; B[model] --&gt; C([results]);\n\n\n\n\n\n\n\nWhat Is a Neural Network?\nNeural Network is just another algorithm for Machine Learning like Random Forest or Gradient Boosting and that’s it! That is a neural network in a nutshell.\nAlthough neural network seems very complex, the beginning of it is quite intuitive as it is inspired by the human brain cells using a mathematical function and it turns out to be a very powerful and flexible function which depends only on its weights. A mathematical proof called the universal approximation theorem shows that this function can solve any problem to any level of accuracy, in theory.\nHowever, in practice there are many caveats to it like the quality of dataset, the hardware computation used to run those neural networks or the trade-off between time and cost of big networks.\nNowadays, the term Deep Learning has replaced Neural Network as nobody build a couple layers of the network anymore. People tends to go deeper like the name suggested. Thanks to its graph-like nature, it is still quickly understandable through visual representation and great resources online help practitioner a lot in doing so.\nAlright but here comes the question — if we have such a good template or so called “architecture” let say a very deep one, then how we are going to train it? how we know that it is optimized with the correct set of weights?\nThe answer is we need a mechanism like in traditional machine learning. But in deep learning, this mechanism is called stochastic gradient descent (SGD). Unlike in the traditional machine learning, SGD is also very flexible and can be used to update weights in every architectures that we can imagine. Here is a process looks like:\n\n\n\n\n\nflowchart LR;\n    A([inputs]) --&gt; C[architecture];\n    B([parameters]) --&gt; C[architecture];\n    C[architecture] --&gt; D([predictions]);\n    D([predictions]) --&gt; E([loss]);\n    E([loss]) -- update --&gt; B([parameters]);\n\n\n\n\n\n\nAs you can see, although we use different terminologies, they are basically the same. The only thing I need to point out is in deep learning, we use SGD to optimize our model parameters.\n\n\nTips and Tricks\nIn machine learning, of course it has a limitation but this should not stop you and I will tell you the important tips and tricks on how to handle it and provide you with an inspiration of its potential so that you will have a solid foundation to be able to complete any task that you are interested in.\nHere is a Machine Learning tips and tricks and Deep Learning Tips and Tricks that I find useful.\n\nSolve a problem with data preprocessing\nThis in my opinion the most powerful tips and tricks that I want to hightlight. As you can see from the example, an image recognizer is very handy when it comes to image classification task.\nBut can it tackle something that is not related to an image? — Actually it can and it can do it pretty well too.\nFor instance, a sound can be converted to a spectrogram, which is a chart that shows the amount of each frequency at each time in an audio file. Fast.ai student Ethan Sutin used this approach to easily beat the published accuracy of a state-of-the-art environmental sound detection model using a dataset of 8,732 urban sounds. fastai’s show_batch clearly shows how each different sound has a quite distinctive spectrogram\n\nA time series can easily be converted into an image by simply plotting the time series on a graph. However, it is often a good idea to try to represent your data in a way that makes it as easy as possible to pull out the most important components. In a time series, things like seasonality and anomalies are most likely to be of interest. There are various transformations available for time series data. For instance, fast.ai student Ignacio Oguiza created images from a time series dataset for olive oil classification, using a technique called Gramian Angular Difference Field (GADF). He then fed those images to an image classification model just like the one you see in this chapter. His results, despite having only 30 training set images, were well over 90% accurate, and close to the state of the art.\n\nIt change our way of thinking as well. It shows that:\n\nDeep learning is very powerful tool for you to use, you just need to find a way to properly represent your data to it\n\nNote that some techniques require only intuition of the data like an environmental sound detection model. However, some demands more in-depth methods to handle the data such as a olive oil classification. Someone might refer to it as “hacky workarounds”.\n\n\nBiases in Dataset\nThere are several ways that you can do that makes your project getting a bias result. Most parts come from the way you handle your data.\n\nData collection\nThe first process that you can give a bias to your data is when you are collecting them. Generally speaking, we’ve seen that most organizations that say they don’t have enough data, actually mean they don’t have enough labeled data. So, they need to gather it.\nI want to pause here a bit. As datasets is very critical to the model like a food. So, throughout the course, think about where the dataset might have come from, and how they might have been curated. Then think about what kinds of interesting datasets you could create for your own projects. Trust me, this will also be a valuable skill for you as a practitioner.\nBack to business, Gathering data might create what so called feedback loops, as describe here:\n\nA predictive policing model is created based on where arrests have been made in the past. In practice, this is not actually predicting crime, but rather predicting arrests, and is therefore partially simply reflecting biases in existing policing processes.\nLaw enforcement officers then might use that model to decide where to focus their police activity, resulting in increased arrests in those areas.\nData on these additional arrests would then be fed back in to retrain future versions of the model.\n\nThis is a positive feedback loop, where the more the model is used, the more biased the data becomes, making the model even more biased, and so forth.\nFeedback loops can also create problems in commercial settings. For instance, a video recommendation system might be biased toward recommending content consumed by the biggest watchers of video (e.g., conspiracy theorists and extremists tend to watch more online video content than the average), resulting in those users increasing their video consumption, resulting in more of those kinds of videos being recommended. We’ll consider this topic more in detail in the later chapter about ethics.\n\n\nValidation Set and Test Set\nIn practice, what you want to do really is making your model working for others. Therefore, validation and evaluation your model are the important steps as well as training which if you have done it properly, we are one step closer to your goal!\nTo do this, our first step was to split our dataset into two sets: the training set (which our model sees in training) and the validation set, also known as the development set (which is used only for evaluation). This lets us test that the model learns lessons from the training data that generalize to new data, the validation data.\nOne way to understand this situation is that, in a sense, we don’t want our model to get good results by “cheating.” If it makes an accurate prediction for a data item, that should be because it has learned characteristics of that kind of item, and not because the model has been shaped by actually having seen that particular item.\nSplitting off our validation data means our model never sees it in training and so is completely untainted by it, and is not cheating in any way. Right?\nIn fact, not necessarily. The situation is more subtle. This is because in realistic scenarios we rarely build a model just by training its weight parameters once. Instead, we are likely to explore many versions of a model through various modeling choices regarding network architecture, learning rates, data augmentation strategies, and other factors we will discuss in upcoming chapters. Many of these choices can be described as choices of hyperparameters. The word reflects that they are parameters about parameters, since they are the higher-level choices that govern the meaning of the weight parameters.\nThe problem is that even though the ordinary training process is only looking at predictions on the training data when it learns values for the weight parameters, the same is not true of us. We, as modelers, are evaluating the model by looking at predictions on the validation data when we decide to explore new hyperparameter values! So subsequent versions of the model are, indirectly, shaped by us having seen the validation data. Just as the automatic training process is in danger of overfitting the training data, we are in danger of overfitting the validation data through human trial and error and exploration.\nThe solution to this conundrum is to introduce another level of even more highly reserved data, the test set. Just as we hold back the validation data from the training process, we must hold back the test set data even from ourselves. It cannot be used to improve the model; it can only be used to evaluate the model at the very end of our efforts. In effect, we define a hierarchy of cuts of our data, based on how fully we want to hide it from training and modeling processes: training data is fully exposed, the validation data is less exposed, and test data is totally hidden. This hierarchy parallels the different kinds of modeling and evaluation processes themselves—the automatic training process with back propagation, the more manual process of trying different hyper-parameters between training sessions, and the assessment of our final result.\nThe test and validation sets should have enough data to ensure that you get a good estimate of your accuracy. If you’re creating a cat detector, for instance, you generally want at least 30 cats in your validation set. That means that if you have a dataset with thousands of items, using the default 20% validation set size may be more than you need. On the other hand, if you have lots of data, using some of it for validation probably doesn’t have any downsides.\nHaving two levels of “reserved data”—a validation set and a test set, with one level representing data that you are virtually hiding from yourself—may seem a bit extreme. But the reason it is often necessary is because models tend to gravitate toward the simplest way to do good predictions (memorization), and we as fallible humans tend to gravitate toward fooling ourselves about how well our models are performing. The discipline of the test set helps us keep ourselves intellectually honest. That doesn’t mean we always need a separate test set—if you have very little data, you may need to just have a validation set—but generally it’s best to use one if at all possible.\nThis same discipline can be critical if you intend to hire a third party to perform modeling work on your behalf. A third party might not understand your requirements accurately, or their incentives might even encourage them to misunderstand them. A good test set can greatly mitigate these risks and let you evaluate whether their work solves your actual problem.\nTo put it bluntly, if you’re a senior decision maker in your organization (or you’re advising senior decision makers), the most important takeaway is this: if you ensure that you really understand what test and validation sets are and why they’re important, then you’ll avoid the single biggest source of failures we’ve seen when organizations decide to use AI. For instance, if you’re considering bringing in an external vendor or service, make sure that you hold out some test data that the vendor never gets to see. Then you check their model on your test data, using a metric that you choose based on what actually matters to you in practice, and you decide what level of performance is adequate. (It’s also a good idea for you to try out some simple baseline yourself, so you know what a really simple model can achieve. Often it’ll turn out that your simple model performs just as well as one produced by an external “expert”!)\n\n\nData Leakage\nThis is a very hard to detect problem as the name suggests. So, it easier to provide an example to you:\nIn the Kaggle distracted driver competition, the independent variables are pictures of drivers at the wheel of a car, and the dependent variables are categories such as texting, eating, or safely looking ahead. Lots of pictures are of the same drivers in different positions. If you were an insurance company building a model from this data, note that you would be most interested in how the model performs on drivers it hasn’t seen before (since you would likely have training data only for a small group of people). In recognition of this, the test data for the competition consists of images of people that don’t appear in the training set.\n\nIf you put one of the images in your training set and one in the validation set, your model will have an easy time making a prediction for the one in the validation set, so it will seem to be performing better than it would on new people. Another perspective is that if you used all the people in training your model, your model might be overfitting to particularities of those specific people, and not just learning the states (texting, eating, etc.).\nAs you can see from the example, there is no single solution to this. So, keep in mind that\n\nUse Judgement in Defining Test Sets.\n\n\n\nBias and Variance Tradeoff\n\nOverfitting is the single most important and challenging issue when training for all machine learning practitioners, and all algorithms. As you will see, it is very easy to create a model that does a great job at making predictions on the exact data it has been trained on, but it is much harder to make accurate predictions on data the model has never seen before. And of course, this is the data that will actually matter in practice. For instance, if you create a handwritten digit classifier and use it to recognize numbers written on checks, then you are never going to see any of the numbers that the model was trained on—checks will have slightly different variations of writing to deal with. You will learn many methods to avoid overfitting in this course.\nHowever, you should only use those methods after you have confirmed that overfitting is actually occurring (i.e., you have actually observed the validation accuracy getting worse during training). We often see practitioners using over-fitting avoidance techniques even when they have enough data that they didn’t need to do so, ending up with a model that may be less accurate than what they could have achieved (i.e., underfitting)\n\nA good model is the one that can generalize well over underlying patterns in the data. Not the model that memorize everything!\n\n\n\nPrediction Is Not a Recommendation\nLast, it is about the misconception of machine learning itself. In my opinion, it is very crucial for you as a practitioner to convey this message to all stakeholders involved in the project\n\nA model only creates predictions, not recommends actions.",
    "crumbs": [
      "Lectures",
      "DL in practice",
      "Whatelse to know to deep learning in practice?"
    ]
  },
  {
    "objectID": "lectures/dl-in-practice/01-deep-learning-in-practice.html#deep-learning-is-not-just-for-image-classification",
    "href": "lectures/dl-in-practice/01-deep-learning-in-practice.html#deep-learning-is-not-just-for-image-classification",
    "title": "Whatelse to know to deep learning in practice?",
    "section": "Deep Learning Is Not Just for Image Classification",
    "text": "Deep Learning Is Not Just for Image Classification\nMost examples usually in computer vision tasks. The reason is that it can be understand easily via a visual representation way of the problem. However, it is not necessary the case. Deep learning is far more valuabe and useful than that.\n\nImage Segmentation\nFor instance, let’s talk about something that is critically important for autonomous vehicles: localizing objects in a picture. If a self-driving car doesn’t know where a pedestrian is, then it doesn’t know how to avoid one! Creating a model that can recognize the content of every individual pixel in an image is called segmentation. Here is how we can train a segmentation model with fastai, using a subset of the Camvid dataset from the paper “Semantic Object Classes in Video: A High-Definition Ground Truth Database” by Gabruel J. Brostow, Julien Fauqueur, and Roberto Cipolla:\n\npath = untar_data(URLs.CAMVID_TINY)\n\n\n\n\n\n\n    \n      \n      100.18% [2318336/2314212 00:00&lt;00:00]\n    \n    \n\n\n\n# Get a glimpse of what an image looks like\nimg = PILImage.create(\"/root/.fastai/data/camvid_tiny/images/0001TP_006750.png\")\nimg.to_thumb(224)\n\n\n\n\n\n\n\n\n\n# Get a glimpse of what a label looks like\nimg = PILImage.create(\"/root/.fastai/data/camvid_tiny/labels/0001TP_006750_P.png\")\nimg.to_thumb(224)\n\n\n\n\n\n\n\n\nA lable is quite hard to see though but there are hilights between each object in the image.\nNext, we prepare DataLoader object like image classification task.\n\ndls = SegmentationDataLoaders.from_label_func(\n    path, fnames=get_image_files(path/\"images\"),\n    label_func=lambda x: path/\"labels\"/f\"{x.stem}_P{x.suffix}\",\n    codes=np.loadtxt(path/\"codes.txt\", dtype=str), bs=8, seed=42\n)\n\nWe need to talk a little bit more about SegmentationDataLoaders and its method from_label_func. Basically, what this object will do is similar to ImageDataLoaders. So, I will focus on the method itself. According to the documentation, this method will create a SegementationDataLoaders from list of fnames in paths with label_func. The key is label_func here:\nWhat it does is to return the an index from the each image filename. Those indicies will then be mapped with codes to be labels in each image.\nLast, it our bs which stands for batch size. It is the number of sampling data that will be trained on SGD at a time.\nLast, we train our learner in this case unet_learner which is a successful architecture for image segmentation task. We also provide resnet as a part of unet architecture.\n\nlearn = unet_learner(dls, resnet34)\nlearn.fine_tune(10)\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\ntime\n\n\n\n\n0\n2.915763\n2.578525\n00:01\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\ntime\n\n\n\n\n0\n1.791474\n1.675884\n00:01\n\n\n1\n1.564460\n1.348752\n00:01\n\n\n2\n1.376029\n1.171540\n00:01\n\n\n3\n1.254213\n1.017833\n00:01\n\n\n4\n1.130328\n0.951614\n00:01\n\n\n5\n1.030382\n0.845308\n00:01\n\n\n6\n0.939838\n0.822760\n00:01\n\n\n7\n0.864249\n0.814584\n00:01\n\n\n8\n0.802218\n0.800724\n00:01\n\n\n9\n0.752931\n0.790928\n00:01\n\n\n\n\n\n\nWe can visualize how well it achieved its task, by asking the model to color-code each pixel of an image. As you can see, it nearly perfectly classifies every pixel in every object. For instance, notice that all of the cars are overlaid with the same color and all of the trees are overlaid with the same color (in each pair of images, the lefthand image is the ground truth label and the right is the prediction from the model):\n\nlearn.show_results(max_n=6, figsize=(7, 8))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSentiment Classification\nOne other area where deep learning has dramatically improved in the last couple of years is natural language processing (NLP). Computers can now generate text, translate automatically from one language to another, analyze comments, label words in sentences, and much more. Here is all of the code necessary to train a model that can classify the sentiment of a movie review better than anything that existed in the world just five years ago. We will use the “IMDb Large Movie Review dataset” from the paper “Learning Word Vectors for Sentiment Analysis” by Andrew Maas et al:\nLike previous examples, we need to download dataset first.\n\npath = untar_data(URLs.IMDB)\n\n\n\n\n\n\n    \n      \n      100.00% [144441344/144440600 00:01&lt;00:00]\n    \n    \n\n\n\n# Take a look at some of positive reviews\nwith open(\"/root/.fastai/data/imdb/train/pos/5059_7.txt\") as f:\n    txt = f.read()\n\nprint(txt)\n\nWe viewed the vcr and found it to be fascinating. Not knowing anything about this true story, I thought: \"Oh, no, P.Brosnan as an American Indian ('red' Indian in the film), what a bad choice\" until I discovered the truth about Grey Owl. The film does a good job of demonstrating the dignity of these native peoples and undermining the racist myths about them. And Annie Galipeau, WOW, what a beauty, and very convincing as an Indian woman (I believe she is French-Canadian; she sure reverts to the all-too familiar speech of such). In spite, of Brosnan's detached, grunting style, in the end he comes through convincingly as a passionate, dedicated man. The plot is a little weak in demostrating his conversion from trapper to animal coservationist. Good film, highly recommended.\n\n\n\n# Take a look at some of negative reviews\nwith open(\"/root/.fastai/data/imdb/train/neg/7141_3.txt\") as f:\n    txt = f.read()\n\nprint(txt)\n\nOkay so I went into this movie not really expecting much I figured an action flick similar to The Fast and the Furious. Some nice cars some nice girls somewhat of a decent plot. Unfortunately I would have to say that this was probably the worst movie I have seen this year. Don't get me wrong the cars were nice and the girls were OK but the way they put the movie together was just plain crappy to put it nicely. The story just never made you care about the cast and the movie seemed just pieced together. So overall this movie was not the worst thing ever by far but if your looking for a movie to go to this weekend I would pass on this one for now.\n\n\nNext, let’s build TextDataLoaders using from_folder to create imagenet style dataset in path with train and valid subfolders (or provide valid_pct).\n\ndls = TextDataLoaders.from_folder(untar_data(URLs.IMDB), valid='test')\n\n\n\n\n\n\n\n\nNote that we provide valid as “test” because of the folder name.\nLast, using text_classifier_learner and AWD_LSTM architecture.\n\nlearn = text_classifier_learner(dls, AWD_LSTM, drop_mult=0.5, metrics=accuracy)\nlearn.fine_tune(4, 1e-2)\n\n\n\n\n\n\n    \n      \n      100.00% [105070592/105067061 00:01&lt;00:00]\n    \n    \n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.461787\n0.411839\n0.810760\n03:20\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.315260\n0.248558\n0.899240\n06:39\n\n\n1\n0.231946\n0.193859\n0.924000\n06:44\n\n\n2\n0.193754\n0.186784\n0.928080\n06:40\n\n\n3\n0.144128\n0.200959\n0.925600\n06:41\n\n\n\n\n\n\nThere are some options that I would like to point out. First, it is drop_mult. According to the documentation, it controls all the amount of “dropout” — a technique used to make the model more generalized, reducing the change of overfitting. Second, it is the value 1e-2. This is “learning rate” which is a hyperparameter in SGD. Basically, it is like a step size of learning. The lower the value is, the slower training process is and hopefully more well-trained model received.\n\n\n\n\n\n\nTip\n\n\n\nIf you ever have any questions about a fastai method, you should use the function doc, passing it the method name:\ndoc(learn.predict)\n\n\nLet’s move on to something much less sexy, but perhaps significantly more widely commercially useful: building models from plain tabular data.\n\n\nTabular Data\nIt is a type of data that is in the form of a table, such as from a spreadsheet, database, or CSV file. A tabular model is a model that tries to predict one column of a table based on information in other columns of the table.\nHere is the code necessary to train a model that will predict whether a person is a high-income earner, based on their socioeconomic background:\n\npath = untar_data(URLs.ADULT_SAMPLE)\n\ndls = TabularDataLoaders.from_csv(path/'adult.csv', path=path, y_names=\"salary\",\n    cat_names = ['workclass', 'education', 'marital-status', 'occupation',\n                 'relationship', 'race'],\n    cont_names = ['age', 'fnlwgt', 'education-num'],\n    procs = [Categorify, FillMissing, Normalize])\n\nlearn = tabular_learner(dls, metrics=accuracy)\n\nThere are various things to note: * TabularDataLoaders uses from_csv method to load data from downloaded adult.csv file. * y_names is for a target column * cat_names is for categorical features * cont_names is for continuous features * procs is the steps for pre-processing data before entering the model such as: * Categorify means categorical encoding: Convert categories into numerical representation * Normalize means “Normalization” — the technique to eliminate the unit aspect of numerical data\nLast, since there is no pretrained model available for this task (in general, pretrained models are not widely available for any tabular modeling tasks, although some organizations have created them for internal use), so we don’t use fine_tune in this case. Instead we use fit_one_cycle, the most commonly used method for training fastai models from scratch (i.e. without transfer learning):\n\nlearn.fit_one_cycle(3)\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.391232\n0.355708\n0.837070\n00:04\n\n\n1\n0.364654\n0.343000\n0.842598\n00:05\n\n\n2\n0.358486\n0.340704\n0.846898\n00:04\n\n\n\n\n\n\nThis model is using the Adult dataset, from the paper “Scaling Up the Accuracy of Naive-Bayes Classifiers: a Decision-Tree Hybrid” by Rob Kohavi, which contains some demographic data about individuals (like their education, marital status, race, sex, and whether or not they have an annual income greater than $50k).\n\n\nRecommendation System\nLet’s look at one more. Recommendation systems are very important, particularly in e-commerce. Companies like Amazon and Netflix try hard to recommend products or movies that users might like. Here’s how to train a model that will predict movies people might like, based on their previous viewing habits, using the MovieLens dataset:\n\npath = untar_data(URLs.ML_SAMPLE)\n\ndls = CollabDataLoaders.from_csv(path/'ratings.csv')\n\nlearn = collab_learner(dls, y_range=(0.5,5.5))\nlearn.fine_tune(10)\n\n\n\n\n\n\n    \n      \n      110.72% [57344/51790 00:00&lt;00:00]\n    \n    \n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\ntime\n\n\n\n\n0\n1.504237\n1.424283\n00:00\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\ntime\n\n\n\n\n0\n1.373108\n1.367214\n00:00\n\n\n1\n1.271707\n1.195855\n00:00\n\n\n2\n1.038150\n0.891961\n00:00\n\n\n3\n0.809098\n0.742112\n00:00\n\n\n4\n0.688838\n0.704049\n00:00\n\n\n5\n0.646945\n0.690868\n00:00\n\n\n6\n0.626341\n0.685442\n00:00\n\n\n7\n0.604875\n0.683328\n00:00\n\n\n8\n0.606573\n0.682748\n00:00\n\n\n9\n0.600661\n0.682595\n00:00\n\n\n\n\n\n\nThis model is predicting movie ratings on a scale of 0.5 to 5.0 to within around 0.6 average error. Since we’re predicting a continuous number, rather than a category, we have to tell fastai what range our target has, using the y_range parameter.\nAlthough we’re not actually using a pretrained model (for the same reason that we didn’t for the tabular model), this example shows that fastai lets us use fine_tune anyway in this case. Sometimes it’s best to experiment with fine_tune versus fit_one_cycle to see which works best for your dataset.\nWe can use the same show_results call we saw earlier to view a few examples of user and movie IDs, actual ratings, and predictions:\n\nlearn.show_results()\n\n\n\n\n\n\n\n\n\n\n\n\n\nuserId\nmovieId\nrating\nrating_pred\n\n\n\n\n0\n8.0\n80.0\n4.0\n4.326948\n\n\n1\n79.0\n58.0\n5.0\n4.278591\n\n\n2\n36.0\n15.0\n4.0\n4.152308\n\n\n3\n76.0\n65.0\n4.0\n3.322256\n\n\n4\n17.0\n20.0\n5.0\n4.176706\n\n\n5\n65.0\n80.0\n4.5\n3.973742\n\n\n6\n74.0\n25.0\n3.0\n3.568486\n\n\n7\n43.0\n26.0\n4.0\n3.550551\n\n\n8\n99.0\n15.0\n4.5\n4.204627",
    "crumbs": [
      "Lectures",
      "DL in practice",
      "Whatelse to know to deep learning in practice?"
    ]
  },
  {
    "objectID": "lectures/dl-in-practice/01-deep-learning-in-practice.html#questionnaire",
    "href": "lectures/dl-in-practice/01-deep-learning-in-practice.html#questionnaire",
    "title": "Whatelse to know to deep learning in practice?",
    "section": "Questionnaire",
    "text": "Questionnaire\nAll the answers are in the text of the chapter of the book, so if you’re not sure about anything here, reread that part of the text and make sure you understand it.\nFor more questions, including detailed answers and links to the video timeline, have a look at Radek Osmulski’s aiquizzes.\n\nDo you need these for deep learning?\n\nLots of math T/F\nLots of data T/F\nLots of expensive computers T/F\nA PhD T/F\n\n\n\n\nSolution\n\n\nLots of math: F\nLots of data: F\nLots of expensive computers: F\nA PhD: F\n\n\n\nName five areas where deep learning is now the best in the world.\n\n\n\nSolution\n\n\nGames: Playing Go and Starcraft\nNLP: LLMs — a large language model capable of predicting the next word\nComputer Vision: Image classification like AlexNet\nGenerative AI: Image generation and video generation\nRecommendation Systems: Movie recommendation\n\n\n\nWhat was the name of the first device that was based on the principle of the artificial neuron?f\n\n\n\nSolution\n\nThe Mark I Perceptron\n\n\nBased on the book of the same name, what are the requirements for parallel distributed processing (PDP)?\n\n\n\nSolution\n\n\nA set of processing units\nA state of activation\nAn output function for each unit\nA pattern of connectivity among units\nA propagation rule for propagating patterns of activities through the network of connectivities\nAn activation rule for combining the inputs impinging on a unit with the current state of that unit to produce an output for the unit\nA learning rule whereby patterns of connectivity are modified by experience\nAn environment within which the system must operate\n\n\n\nWhat were the two theoretical misunderstandings that held back the field of neural networks?\n\n\n\nSolution\n\nThe first one is the failure of the NN to handle simple XOR operation on a single layer and the second one is the statement which state that one extra layer of NN can solve any problem but it is slower and impossible to be useful in practice.\n\n\nWhat is a GPU?\n\n\n\nSolution\n\nGPU stands for Graphical Processing Unit. It is vital for training a deep learning model due to its parallelized nature of computation.\n\n\nOpen a notebook and execute a cell containing: 1+1. What happens?\n\n\n\nSolution\n\n2\n\n\nFollow through each cell of the stripped version of the notebook for this chapter. Before executing each cell, guess what will happen.\n\n\n\nSolution\n\nAll done through this documenation!\n\n\nComplete the Jupyter Notebook online appendix.\n\n\n\nSolution\n\nAll done through this documenation and experimentation!\n\n\nWhy is it hard to use a traditional computer program to recognize images in a photo?\n\n\n\nSolution\n\nIn traditional programming, you need to give a step-by-step instruction to program an application what to behave. On the other hand, Machine learning gives a computer ability to learn without being explicitly programmed.\n\n\nWhat did Samuel mean by “weight assignment”?\n\n\n\nSolution\n\nA process to determine the model parameters. Those weights at the end of the day need to give the model ability to complete a task. In other words, it needs to successfully transform inputs to outputs as intended.\n\n\nWhat term do we normally use in deep learning for what Samuel called “weights”?\n\n\n\nSolution\n\nModel parameters\n\n\nDraw a picture that summarizes Samuel’s view of a machine learning model.\n\n\n\nSolution\n\nRefer to the a complete process of machine learning.\n\n\nWhy is it hard to understand why a deep learning model makes a particular prediction?\n\n\n\nSolution\n\nDue to its non-linearity behaviour from various functions from each node together with its deep architecture that makes those functions even more complex.\n\n\nWhat is the name of the theorem that shows that a neural network can solve any mathematical problem to any level of accuracy?\n\n\n\nSolution\n\nUniversal Approximation Theorem\n\n\nWhat do you need in order to train a model?\n\n\n\nSolution\n\n\nDataset\nPretrained-model\nGPU\n\n\n\nHow could a feedback loop impact the rollout of a predictive policing model?\n\n\n\nSolution\n\nIf biases was made to a dataset and we keep using that dataset to train our model. Then, using our predictions from that model to train the model. It is likely to deviate from the truth. In this case:\n\nA predictive policing model is created based on where arrests have been made in the past. In practice, this is not actually predicting crime, but rather predicting arrests, and is therefore partially simply reflecting biases in existing policing processes.\nLaw enforcement officers then might use that model to decide where to focus their police activity, resulting in increased arrests in those areas.\nData on these additional arrests would then be fed back in to retrain future versions of the model which eventually creating a feedback loop.\n\n\n\nDo we always have to use 224×224-pixel images with the cat recognition model?\n\n\n\nSolution\n\nNo, we don’t. 224x224 size is just a standard size for historical reason as the old pretrained model needs this size exactly. Nowadays, we can pretty much use any size of an image to feed into the model because item_tfms will then resize it to be matched with the model input.\n\n\nWhat is the difference between classification and regression?\n\n\n\nSolution\n\nThey are both supervised-type machine learning models. The key difference is classification is for predicting categorical values like whether an image is a cat or a dog. In contrast, regression is something for estimating numerical values like a price of a car from various attributes such as colors and car models.\n\n\nWhat is a validation set? What is a test set? Why do we need them?\n\n\n\nSolution\n\nValidation set is a portion of your dataset used to test the performance of the training process of the model such as model parameter evaluation and hyperparameter evaluation. This set also known as “Development Set”.\nTest set is another held-out dataset. We keep it from ourselves in order to eliminate biases during the iterative development process. This set will help ensure that our model actually generalize well on new dataset despite our own choices of hyperparameters.\n\n\nWhat will fastai do if you don’t provide a validation set?\n\n\n\nSolution\n\nautomatically set it to 20% of all dataset you have.\n\n\nCan we always use a random sample for a validation set? Why or why not?\n\n\n\nSolution\n\nWe can’t. The reason is that dataset has its own physical meaning. Consider time-series dataset, if we split data randomly, it will be strange for us to train on the data such as from 25-Dec to 31-Dec and use it to predict on 10-Nov. But it is not necessary the case, some dataset like diabetes classification may be able to split randomly (if we ensure the variety of each patient).\n\n\nWhat is overfitting? Provide an example.\n\n\n\nSolution\n\nOverfiiting is a situation where a model can memorize all training samples and can not generalize well on the new dataset. For example, samples with roughly polynomial relationship. If you provide a model to have a this kind of relationship, in practice the model should perform well. However, if you train the model until overfitting occurs, instead of learning a relationship, the model will try to connect all samples together in other words memorize all patterns that it have seen. As a result, when a new data comes in, it can perform very bad due to overfitting situation.\n\n\nWhat is a metric? How does it differ from “loss”?\n\n\n\nSolution\n\nA metric and loss is basically has the same goal which is to measure the performance of the model. The difference is that a metric is for human to quickly see if it is a good model and loss is for model optimization. Therefore, for a metric, the higher the value is, the more useful the model becomes. In contrast, for loss, the lower the value is, the more useful the model becomes.\n\n\nHow can pretrained models help?\n\n\n\nSolution\n\nIt helps save your effort, time and cost. First, effort to gather and label huge amount of data from scratch. Next, saving your training time, usually a pretrained offers you more accurate model and tends to train faster. Last, training a model requires GPU and it is expensive. Therefore, a pretrained model which ususualy does less training time (Thanks to transfer learning technique) can save a lot of money while you stil accomplish your goal.\n\n\nWhat is the “head” of a model?\n\n\n\nSolution\n\nIt is the last part of the model. Usually, it is a part where weight changing and layer adding adapt to a similar task during fine tuning.\n\n\nWhat kinds of features do the early layers of a CNN find? How about the later layers?\n\n\n\nSolution\n\nCNN or Convolutional Neural Network learns basic features in the early layers such as colors and edges. In the latter layers, it will learn more complex features like an ear of a cat or a month of a dog.\n\n\nAre image models only useful for photos?\n\n\n\nSolution\n\nNo really, it depends on how you shape your problem. If you can represent other data types into an image, you are good to go.\n\n\nWhat is an “architecture”?\n\n\n\nSolution\n\nAn architecture is a term referring to a template of neural network structure. It acts as a starter form of the network before gaining weights through experience.\n\n\nWhat is segmentation?\n\n\n\nSolution\n\nSegmentation is a term used in image segmentation task (e.g., object detection). It is used for use-case like building an autonomous vehicle.\n\n\nWhat is y_range used for? When do we need it?\n\n\n\nSolution\n\ny_range is a parameter used in a technique callled “Collaborative Filtering”. It is used to define the range of values when predicting a numerical value in recommadation system.\n\n\nWhat are “hyperparameters”?\n\n\n\nSolution\n\nHyperparameters are choices that used to tweak a model in a high level such as architectures or learning rate. They are important for improving the efficiency of your model and they are figured out by trial-and-error process.\n\n\nWhat’s the best way to avoid failures when using AI in an organization?\n\n\n\nSolution\n\nIn short, make sure that you do not fool yourself. The best way is to split the data into 3 set: Training set, Validation set and Test set. These dataset serve different purpose. The first and second ones are for training and model evaluation while you are developing your model. The last one is to ensure that your model is good to go in the production without any bias elsewhere.\n\nFor a complete solutions, See Fastbook Chapter 1 Questionnaire Solutions\n\nFurther Research\n\nWhy is a GPU useful for deep learning? How is a CPU different, and why is it less effective for deep learning?\n\n\n\nSolution\n\nGPU is good in parallelism. It can do multiple and small computations at the same time. For example, displaying billion of pixel of a 4K-60FPS streaming video synchronously. Generally speaking, in deep learning we use its benefit to training the model faster by running SGD in batches to update set of weight in the architecture. The key difference to CPU is while GPU can handle small computations simultaneously, CPU does not. It is made to handle a complex task one at a time such as reading sets of instruction in a computer sequentially. Therefore, in deep learning which has small computations thousands of times to update weights, GPU is more suitable for this task as operations in the training process do not require any complex computation at all (They are just adding and multiplication of matrix!). Therefore, GPU should be the hardware of your choice when doing deep learning.\n\n\nTry to think of three areas where feedback loops might impact the use of machine learning. See if you can find documented examples of that happening in practice.\n\n\n\nSolution\n\n\nIn human resources, let’s say you want to create a model that find talented candidates for an application. This is very hard problem in practice as most of the data come from the past which may not be diverse enough or have changed through era. Here is an example of Amazon ditched AI recruiting tool that favored men for technical jobs in practice.\nIn movie recommendation system, it highly depends on the user interaction which can lead to narrow sets of recommendations and limits your user experience.\nIn load approval systems, some features like races and social economic background can cause the machine to be bias over time as the model learns from those demographic data whether to approve for a load in the past.\n\n\nThis notebook is adapted from Chapter 1 - Intro of Deep Learning for Coders with Fastai and PyTorch: AI Applications Without a PhD.",
    "crumbs": [
      "Lectures",
      "DL in practice",
      "Whatelse to know to deep learning in practice?"
    ]
  },
  {
    "objectID": "lectures/dl-in-practice/01-pre-trained-model.html#introduction",
    "href": "lectures/dl-in-practice/01-pre-trained-model.html#introduction",
    "title": "Is it a bird? — The power of pretrained-model",
    "section": "Introduction",
    "text": "Introduction\nIn 2015 the idea of creating a computer system that could recognise birds was considered so outrageously challenging that it was the basis of this XKCD joke:\n\nBut today, we can do exactly that, in just a few minutes, using entirely free resources!\nThe basic steps we’ll take are:\n\nUse DuckDuckGo to search for images of “bird photos”\nUse DuckDuckGo to search for images of “forest photos”\nFine-tune a pretrained neural network to recognise these two groups\nTry running this model on a picture of a bird and see if it works.",
    "crumbs": [
      "Lectures",
      "DL in practice",
      "Is it a bird? — The power of pretrained-model"
    ]
  },
  {
    "objectID": "lectures/dl-in-practice/01-pre-trained-model.html#setup",
    "href": "lectures/dl-in-practice/01-pre-trained-model.html#setup",
    "title": "Is it a bird? — The power of pretrained-model",
    "section": "Setup",
    "text": "Setup\nFirst, we need to setup an access to Google Drive. This is to persist data or artifacts in a local drive even when we are not connected to Google Colab.\n\nfrom google.colab import drive\ndrive.mount(\"/content/gdrive\")\n\nMounted at /content/gdrive\n\n\nThen, install fastai and duckduckgo-search as necessary dependencies and import them.\n\n!python -m pip install -Uqq fastai duckduckgo-search\n\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.7/5.7 MB 28.8 MB/s eta 0:00:00\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.0/8.0 MB 52.7 MB/s eta 0:00:00\n\n\n\nfrom duckduckgo_search import DDGS\nfrom fastai.vision.all import *\nfrom fastcore.all import *\nfrom fastdownload import download_url\nfrom time import sleep",
    "crumbs": [
      "Lectures",
      "DL in practice",
      "Is it a bird? — The power of pretrained-model"
    ]
  },
  {
    "objectID": "lectures/dl-in-practice/01-pre-trained-model.html#step-1-download-images-of-birds-and-non-birds",
    "href": "lectures/dl-in-practice/01-pre-trained-model.html#step-1-download-images-of-birds-and-non-birds",
    "title": "Is it a bird? — The power of pretrained-model",
    "section": "Step 1: Download images of birds and non-birds",
    "text": "Step 1: Download images of birds and non-birds\nLet’s start by searching for a bird photo and seeing what kind of result we get. We’ll start by getting URLs from a search:\nFirst, we define a helper function called search_image to get downloadable image links. And try searching for a bird photo.\n\n\nCode\ndef search_images(term, max_images=30):\n    \"\"\"\n    Get image urls from the given term.\n    \"\"\"\n    with DDGS() as ddgs:\n        ddgs_images_gen = ddgs.images(\n            term,\n            max_results=max_images\n        )\n\n        print(f\"Searching for '{term}' ...\")\n        urls = L(ddgs_images_gen).itemgot(\"image\")\n\n    return urls\n\n\n\nurls = search_images('bird photos', max_images=1)\nurls[0]\n\nSearching for 'bird photos' ...\n\n\n'https://images.pexels.com/photos/1661179/pexels-photo-1661179.jpeg?cs=srgb&dl=green-bird-1661179.jpg&fm=jpg'\n\n\nNote that DuckDuckGo get an image urls from text search not image search. That is why we have to include photos in the keyword.\n…and then download a URL and take a look at it:\n\ndest = \"gdrive/My Drive/practical-deep-learning/bin/bird.jpg\"\ndownload_url(urls[0], dest, show_progress=False)\n\nim = Image.open(dest)\nsim = im.to_thumb(256, 256)\nsim\n\n\n\n\n\n\n\nFigure 1: Example of a bird photo\n\n\n\n\n\nto_thumb method is for resizing an image to be able to used few resources to show on the output. Also, note that the shape of an image is defined by its height and width respectively.\n\nsim.shape\n\n(256, 219)\n\n\nNow let’s do the same with “forest photos”:\n\ndest = \"gdrive/My Drive/practical-deep-learning/bin/forest.jpg\"\ndownload_url(search_images('forest photos', max_images=1)[0], dest, show_progress=False)\n\nImage.open(dest).to_thumb(256, 256)\n\nSearching for 'forest photos' ...\n\n\n\n\n\n\n\n\nFigure 2: Example of a forest photo\n\n\n\n\n\nOur searches seem to be giving reasonable results, so let’s grab a few examples of each of “bird” and “forest” photos, and save each group of photos to a different folder (I’m also trying to grab a range of lighting conditions here):\n\nsearches = \"forest\", \"bird\"\nconditions = \"sun\", \"shade\"\npath = Path(\"gdrive/My Drive/practical-deep-learning/bin/bird-or-not\")\n\nfor s in searches:\n    dest = path/s\n    dest.mkdir(exist_ok=True, parents=True)\n\n    # Pause between searches to avoid over-loading server\n    download_images(dest, urls=search_images(f\"{s} photo\"))\n    sleep(10)\n\n    for c in conditions:\n        download_images(dest, urls=search_images(f\"{s} {c} photo\"))\n        sleep(10)\n\n    resize_images(dest, max_size=400, dest=dest)\n\nSearching for 'forest photo' ...\nSearching for 'forest sun photo' ...\nSearching for 'forest shade photo' ...\nSearching for 'bird photo' ...\nSearching for 'bird sun photo' ...\nSearching for 'bird shade photo' ...\n\n\nNote that resize_images operates recursively by overwriting files in dest. Also, it is reducing the file size to the limited max_size so that we can keep data in a local drive.",
    "crumbs": [
      "Lectures",
      "DL in practice",
      "Is it a bird? — The power of pretrained-model"
    ]
  },
  {
    "objectID": "lectures/dl-in-practice/01-pre-trained-model.html#step-2-train-our-model",
    "href": "lectures/dl-in-practice/01-pre-trained-model.html#step-2-train-our-model",
    "title": "Is it a bird? — The power of pretrained-model",
    "section": "Step 2: Train our model",
    "text": "Step 2: Train our model\nSome photos might not download correctly which could cause our model training to fail, so we’ll remove them permanetly from disk:\n\nfailed = verify_images(get_image_files(path))\nfailed.map(Path.unlink)\n\nprint(f\"Removed {len(failed)} invalid images!\")\n\nRemoved 6 invalid images!\n\n\nTo train a model, we’ll need DataLoaders, which is an object that contains a training set (the images used to create a model) and a validation set (the images used to check the accuracy of a model – not used during training). In fastai we can create that easily using a DataBlock, and view sample images from it:\n\ndls = DataBlock(\n    blocks=(ImageBlock, CategoryBlock),\n    get_items=get_image_files,\n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=[Resize(192, method='squish')]\n).dataloaders(path, bs=32)\n\ndls.show_batch(max_n=6)\n\n\n\n\n\n\n\nFigure 3: Example of images in a batch\n\n\n\n\n\nHere what each of the DataBlock parameters means:\nblocks=(ImageBlock, CategoryBlock),\nThe inputs to our model are images, and the outputs are categories (in this case, “bird” or “forest”).\nget_items=get_image_files,\nTo find all the inputs to our model, run the get_image_files function (which returns a list of all image files in a path).\nsplitter=RandomSplitter(valid_pct=0.2, seed=42),\nSplit the data into training and validation sets randomly, using 20% of the data for the validation set.\nget_y=parent_label,\nThe labels (y values) is the name of the parent of each file (i.e. the name of the folder they’re in, which will be bird or forest).\nitem_tfms=[Resize(192, method='squish')]\nBefore training, resize each image to 192x192 pixels by “squishing” it (as opposed to cropping it).\nNow we’re ready to train our model. The fastest widely used computer vision model is resnet18. You can train this in a few minutes, even on a CPU! (On a GPU, it generally takes under 10 seconds…)\nfastai comes with a helpful fine_tune() method which automatically uses best practices for fine tuning a pre-trained model, so we’ll use that.\n\nlearn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(3)\n\nDownloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n100%|██████████| 44.7M/44.7M [00:00&lt;00:00, 123MB/s]\n\n\n\n\nTable 1: Fine Tuning Results\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.881389\n0.016011\n0.000000\n00:37\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.110143\n0.000960\n0.000000\n00:58\n\n\n1\n0.060484\n0.000762\n0.000000\n00:55\n\n\n2\n0.041855\n0.001080\n0.000000\n00:51\n\n\n\n\n\n\n\n\n\nGenerally when I run this I see 100% accuracy on the validation set (although it might vary a bit from run to run).\n“Fine-tuning” a model means that we’re starting with a model someone else has trained using some other dataset (called the pretrained model), and adjusting the weights a little bit so that the model learns to recognise your particular dataset. In this case, the pretrained model was trained to recognise photos in imagenet, and widely-used computer vision dataset with images covering 1000 categories).\nFor details on fine-tuning (or in general, transfer learning) and why it’s important, check out the Whatelse to know to deep learning in practice?\nAs a side note here, although the fine_tune method was trained on 3 epoch, you can see that it needs additional epoch to modify some weight and architecture to match with our problem. That’s why we have the first result table shown.",
    "crumbs": [
      "Lectures",
      "DL in practice",
      "Is it a bird? — The power of pretrained-model"
    ]
  },
  {
    "objectID": "lectures/dl-in-practice/01-pre-trained-model.html#step-3-use-our-model-and-build-your-own",
    "href": "lectures/dl-in-practice/01-pre-trained-model.html#step-3-use-our-model-and-build-your-own",
    "title": "Is it a bird? — The power of pretrained-model",
    "section": "Step 3: Use our model (and build your own!)",
    "text": "Step 3: Use our model (and build your own!)\nLet’s see what our model thinks about that bird we downloaded at the start:\n\nis_bird, _, probs = learn.predict(PILImage.create(\"gdrive/My Drive/practical-deep-learning/bin/bird.jpg\"))\n\nprint(f\"This is a: {is_bird}.\")\nprint(f\"Probability it's a bird: {probs[0]:.4f}\")\n\n\n\n\n\n\n\n\nThis is a: bird.\nProbability it's a bird: 0.9999\n\n\nNote that predict method needs to accept TensorImage as an argument so an object called PILImage or PillowImage was used. Also, it returns 3 outputs:\n\na label whether the given image is a bird or forest\na label as tensor in this case (single-label classification): 0 or 1\nprobabilities of each class\n\nGood job, resnet18. :)\nSo, as you see, in the space of a few years, creating computer vision classification models has gone from “so hard it’s a joke” to “trivially easy and free”!\nIt’s not just in computer vision. Thanks to deep learning, computers can now do many things which seemed impossible just a few years ago, including creating amazing artworks, and explaining jokes. It’s moving so fast that even experts in the field have trouble predicting how it’s going to impact society in the coming years.\nOne thing is clear – it’s important that we all do our best to understand this technology, because otherwise we’ll get left behind!\nReference: Is it a bird? Creating a model from your own data",
    "crumbs": [
      "Lectures",
      "DL in practice",
      "Is it a bird? — The power of pretrained-model"
    ]
  },
  {
    "objectID": "projects/horapa-vs-kaprao.html#introduction",
    "href": "projects/horapa-vs-kaprao.html#introduction",
    "title": "Is it actually holy basil?",
    "section": "Introduction",
    "text": "Introduction\nScenario: What would be happier than eating good food? Except one thing that blocks you from doing that Horapa or Thai Basil.\nIn Thailand, favourite main dish of most people would be Minched Pork Kaprao (Holy Basil) with fried egg like this image:\n\nHowever, it is quite hard for an excellent cook like you to eyeball and pick which one is Kaprao or Horapa. If you choose the wrong ingredient, this can cause negative effect to the taste of the delicious Kaprao and you do not want it to happen Right?\nTherefore, the objective of this project is to let the machine help you classify which one is Kaprao that you want and ditch the ugly taste (in my opinion) Horapa out!",
    "crumbs": [
      "Projects",
      "Is it actually holy basil?"
    ]
  },
  {
    "objectID": "projects/horapa-vs-kaprao.html#setup",
    "href": "projects/horapa-vs-kaprao.html#setup",
    "title": "Is it actually holy basil?",
    "section": "Setup",
    "text": "Setup\nFirst, we need to setup an access to Google Drive. This is to persist data or artifacts in a local drive even when we are not connected to Google Colab.\n\nfrom google.colab import drive\ndrive.mount(\"/content/gdrive\")\n\nMounted at /content/gdrive\n\n\nThen, install fastai and duckduckgo-search as necessary dependencies and import them.\n\n!pip install -Uqq fastai duckduckgo-search\n\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.7/5.7 MB 22.7 MB/s eta 0:00:00\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.0/8.0 MB 49.3 MB/s eta 0:00:00\n\n\nNext, we need to download dataset. Here I use git clone to download a repo which contains our dataset to local runtime. After that, unzip -d to extract and move them to mounted Google Drive. Don’t forget to mkdir before hand.\n\n!git clone https://github.com/TAUTOLOGY-EDUCATION/DATASET.git\n\nCloning into 'DATASET'...\nremote: Enumerating objects: 1301, done.\nremote: Counting objects: 100% (16/16), done.\nremote: Compressing objects: 100% (12/12), done.\nremote: Total 1301 (delta 4), reused 12 (delta 3), pack-reused 1285\nReceiving objects: 100% (1301/1301), 1.96 GiB | 38.53 MiB/s, done.\nResolving deltas: 100% (12/12), done.\nFiltering content: 100% (3/3), 5.02 GiB | 55.93 MiB/s, done.\n\n\n\n!mkdir -p \"gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data\"\n!unzip /content/DATASET/HorapaVsKaprao/horapa-01.zip -d \"gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data\" && unzip /content/DATASET/HorapaVsKaprao/kaprao.zip -d \"gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data\"\n\nArchive:  /content/DATASET/HorapaVsKaprao/horapa-01.zip\n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_233046.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_233042(0).jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_233140.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_233148.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_233052.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_233149.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_233112.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_233055.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_233146.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_233047.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_233147.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_233151.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_233049.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_233108.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_233101.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_233111.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_233044.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_233028.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_233051.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_233157.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_233145.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_233024.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_233139.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_233141.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_233019.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_233142.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_233032.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_233015.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_233013.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_233110.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_233017.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_233020.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232933.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232913.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_233041.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_233018.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232910(0).jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_233012.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232922.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_233138.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_233016.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232925(0).jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232930.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232916.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232926.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232936.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_233026.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232927.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232915(0).jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232911.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232923.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232935.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232918.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232921.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232917.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232915.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232858.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232928.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232857.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232840.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232931.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232848.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232907.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232920.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232925.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232855.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232851.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232908.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232843.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232853.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232828.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232827.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232849.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232859.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232914.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232830.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232832.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232836.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232816.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232837.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232839.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232810.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232856(0).jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232831.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232809.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232845.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232841.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232801.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232803.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232829.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232807.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232805.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232753.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232747.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232750.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232846.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232813.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232757.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232702.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232745.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232743.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232759.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232744.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232800.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232804.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232739.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232802.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232756.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232735.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232755.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232754.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232746.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232740.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232741.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232734.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232705.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232742.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232736.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232730.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232710.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232724.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232819.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232731.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232729.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232703.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232720.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232707.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232726.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232709.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232725.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232818.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232713.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232722.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232718.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232715.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232711.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232838.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232708.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232721.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232717.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232719.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232706(0).jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232714.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232700.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232657.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232717(0).jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232701.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232704(0).jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232706.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232909.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232704.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232812.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232702(0).jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232658.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232612.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232624.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232659.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232618.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232648.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232605.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232619.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_233054.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232910.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232625.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232558.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232547.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_233027.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232622.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232550.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232600.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232540.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232557.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232610.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232603.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232614.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232526.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232555.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232531.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232856.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232542.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232523.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232545.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232549.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232525.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232932.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232533.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232530.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232543.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232914(0).jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232504.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232518.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232456.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232444.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232515.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232458.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232447.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232500.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232502.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_233109.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232514.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232929.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232934.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232517.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232455.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232442.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232437.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232446.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_233058.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232430.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_233043.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232439.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232436.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232751.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_233100.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232413.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232412.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232416.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232428.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232407.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_233200.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232432.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_233029.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232410.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232359.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232405.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232415.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232408.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_233048.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_233050.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232406.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232402.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_233056.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232403.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_233202.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232404.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_233057.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232357.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_233144.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232712.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_233154.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232608.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232728.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_233150.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_233014.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232353.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232005.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231955.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232228.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232313.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232252.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232000.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232306.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232351.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232018.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232015.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232335.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232232.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231938.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232340.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232235.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231937.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232328.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232255.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231951.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231940.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231914.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231936.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232321.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231859.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231937(0).jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231905.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231916.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231853.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231934.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231910.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231909.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231854.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231922.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231908.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231847.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231902.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231900.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231836.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231825.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231921.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231912.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231820.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231846.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231822.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232353(0).jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231811.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231821.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231841.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231947.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231813.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_233059.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231818.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231759.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231834.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231756.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232250.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231814.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231722.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231758.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231809.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231724.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231755.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231805.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231706.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231652.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231654.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231715.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231707.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231615(0).jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231709.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231621.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231613.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231633.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231610.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231538.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231522.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231703.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231806.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231534.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231559.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231546.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231647.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231615.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231606(0).jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231531.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231541.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231527.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231525.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231521.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231856.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231631.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231627.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231427.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231425.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_225006.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231436.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_225012(0).jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231518.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231512.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231511.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231711.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_225013.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224957.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231435.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_225003.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224955.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_225007.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_225001.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_225012.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224954.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_225004.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224935.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224941.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224949.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_225010.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224928.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224834.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_233042.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224907.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224926.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224828.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224833.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224856.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224829.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224922.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224902.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224825.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224914.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224824.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224858.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224820.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224835.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224813.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231515.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224812.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224806.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224737.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224804.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224733.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224750.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224743.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224720.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224736.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224742.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224831.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224808.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224816.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224735.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224727.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224730.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224728.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224631.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224629.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231519.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224627.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224613.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224815.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224558.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224617.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224615.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224908.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224619.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224626.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224602.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224604.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224552.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224459.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224548.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224456.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224453.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224436.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224448.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224431.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224342.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224441.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224452.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224500.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224438.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224343.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224444.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224445.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224418.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224426.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224341.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224334.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224601.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224411.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232243.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232349.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224424.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224421.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224332.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224328.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224358.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224333.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224354.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224331.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224630.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232912.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224400.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231952.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224357.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224329.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224313.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224330.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232342.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232308.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224349.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232008.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231958.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232017.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232246.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224356.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232325.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224348.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224422.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232324.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232919.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224310.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224308(0).jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224305.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224256.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224312.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224346.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224347.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224345.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224249.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224158.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231957.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224929.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224247.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224151.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224233.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224245.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224241.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224156.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224306.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224145.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224157.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224308.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224235.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224153.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224131.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224304.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232811.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_221644.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224133.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224128.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232318.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_221625.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_221620.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224129.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_221624.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224142.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224006.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_221623.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224126.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_221628.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224135.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224001.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224123.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_221611.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224008.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224011.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224009.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224148.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224311.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_221604.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_221609.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224000.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_221608.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_231606.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_221614.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_221550.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_223950.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224132.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_232538.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_223941.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_221551.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_223809.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_223801.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_221602.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_223811.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_221548.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_223807.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_221549.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_221542.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_221543.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_223757.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_221546.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_223756.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224338.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_223805.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_221541.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_221544.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_221530.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224622.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_223751.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_224336.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_221539.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_223753.jpg  \nArchive:  /content/DATASET/HorapaVsKaprao/kaprao.zip\n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_220654.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_220819(0).jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_220701.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_220642.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_220704.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_220639.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_220802.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_220753.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_220732.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_220751.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_220748.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_220820.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_220758.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_220744.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_220823.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_220819.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_220659.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_220759.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_220703.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_220705.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_220707.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_220734.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_220825.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_220822(0).jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_220702.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_220656.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_220822.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_220821.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_220700.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_220817.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_220638.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_220730.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214859.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_215016.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214958.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_215015.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_215019.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_220634.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214848.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_215021.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_215022.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_220633.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_215003.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_215027.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_215025.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_215008.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214858.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_220637.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214949.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214829.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214843.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214840.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214847.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_215006.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214845.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_220731.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214855.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214850.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_215018.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214753.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214835.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214833.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214825.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214820.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214748.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214616.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214719.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214708.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214737.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214751.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214743.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214811.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214655.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214721.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214704.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214744.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214646.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214603.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214822.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214608.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214557.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214638.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214614.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214649.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214619.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214827.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214557(0).jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214533.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214612.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214555.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214610.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214633.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214501.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214538.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214428.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214448.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214437.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214435.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214450.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214543.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214518.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214431.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214356.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214419.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214347.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214502.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214426.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214433.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214453.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214249.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214406.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214454.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214458.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214343.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214354.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214359.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214407.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214251.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214250.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214246.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214241.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214216.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214247.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214235.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214238.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214233.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214231(0).jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214243.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214239.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214218.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214236.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214231.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214234.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214224.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214237.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214225.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214226.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214222.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214230.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214232.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214227.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214341.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214220.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214213.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214221.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214223.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214048.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214208.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214217.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214210.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214026.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214051.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214020.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214212.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214215.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214219.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214107.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214013.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214057.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214101.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213336.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213946.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213340.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214036.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214039.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213338.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214228.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213342.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214000.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213329.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213320.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213939.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213937.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214104.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213928.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213246.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213322.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213950.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213909.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213916.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213213.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213251.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213912.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213905.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213302.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213305.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213914.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213912(0).jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213931.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213240.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213904.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213223.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213317.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213245.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213236.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213219.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213855.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213216.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213210.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213852.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213847.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213846.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213850.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213159.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213149.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213907.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213147.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213842.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213141.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213831.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213137.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213133.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213825.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213840.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213143.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213806.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213135.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213812.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213820.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213109.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213838.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213111.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213018.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213107.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213833.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213055.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213033.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213822.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213054.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_214214.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213804.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213726.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213758.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213014.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213029.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213755.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213800.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213030.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213752.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210351.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213741.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213705.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213702.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213736.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210356.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210343.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213732.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210354.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213708.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213012.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210326.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213720.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210346.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213023.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213717.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210350.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210259.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213706.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210309.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210325.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210316.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210338.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210321.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210336.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213655.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213700.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213650.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213624.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213642.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213621.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210250.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213633.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213626.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213632.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213620.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210234.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213640.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210258.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210257.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213644.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210251.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210252.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213841.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210237.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213514.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213520.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210240.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213513.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210236.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213517.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210224.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213516.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213511.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210209.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210222.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210220.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213510.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213505.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213458.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213447.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210153.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210218.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210215.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210146.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213508.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210204.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213453.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213502.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213440.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210156.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213448.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213457.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210154.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210148.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210149.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210155.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210213.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210141.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213410.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210143.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213412.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210117.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210140.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210127.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213432.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210138.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213425.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213403.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210139.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210105.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213429.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210104.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210125.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213401.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210120.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213407.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210108.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210116.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210103.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210042.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210039.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210123.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213434.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210109.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210054.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210040.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210111.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210057.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210035.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210008.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213356.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210037.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_213345.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210100.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210012.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205955.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210038.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205953.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210030.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210011.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210034.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210029.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205927.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_210031.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205919.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205952.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205954.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205906.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205922.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205919(0).jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205910.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205908.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205924.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205909(0).jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205924(0).jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205921.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205925.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205914.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205901(0).jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205923.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205912.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205902.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205313.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205901.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205913.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205917.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205920.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205915.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205907.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205911.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205305.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205912(0).jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205904.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205909.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205907(0).jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205306.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205851(0).jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205859(0).jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205304.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205312.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205857.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205309.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205857(0).jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205301(0).jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205850.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205303.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205658.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205849.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205301.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205858.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205859.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205258.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205659.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205259.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205849(0).jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205256.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205252.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205255.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205254.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205848(0).jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205848.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205642.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205251.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205250.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205851.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205246.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205647.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205253.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205657.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205641.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205242.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205653.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205238.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205646.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205234.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205635.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205652.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205610.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205608.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205236.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205225(0).jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205656.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205219.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205227.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205617(0).jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205216.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205611(0).jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205225.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205233.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205629.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205627.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205223.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205616.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205623(0).jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205221.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205621.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205613.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205615.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205217.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205158.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205621(0).jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205213.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205145.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205202.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205618.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205204.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205623.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205620.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205619.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205158(0).jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205617.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205149.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205615(0).jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205611.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205153.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205154.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205609.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205613(0).jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205152.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205609(0).jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205148.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205240.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205151.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205612.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205150.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205606.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205148(0).jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205146.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205147.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205144.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205607.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205614.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205145(0).jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205604.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205131.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205605.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205143.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205136.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205601.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205558(0).jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205134.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205603.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205600.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205137.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205558.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205135.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205142.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205555.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205556.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205130(0).jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205133(0).jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205130.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205554.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205559.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205132.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205548.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205550.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205553.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205133.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205017.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205129.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205124.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205552.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205122.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205128.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205541.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205540.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205542.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205019(0).jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205546.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205538.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205544.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205543.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205545.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205026.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205125.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205539.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205021(0).jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205028.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205402.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205029(0).jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205028(0).jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205027.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205029.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205023(0).jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205535.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205356.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205537.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205024.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205026(0).jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205023.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205014.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205403.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205015.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205357.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205022.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205400.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205021.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205358.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205020.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205359.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205349.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205013.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205354.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205355.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205228.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205354(0).jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_205018.jpg  \n  inflating: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao/20220425_204945.jpg  \n\n\n\n!ls \"gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data\"\n\nhorapa  kapao\n\n\nAs you can see the kapao folder is mispelling. So, we have to change it to the correct one first before we do labelling process.\nNote that as we will use folder names to label images, the order of the folders will be an index to each label. In this case, 0 - horapa and 1 - kaprao.\n\n!mv \"gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kapao\" \"gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kaprao\"",
    "crumbs": [
      "Projects",
      "Is it actually holy basil?"
    ]
  },
  {
    "objectID": "projects/horapa-vs-kaprao.html#data-preprocessing",
    "href": "projects/horapa-vs-kaprao.html#data-preprocessing",
    "title": "Is it actually holy basil?",
    "section": "Data Preprocessing",
    "text": "Data Preprocessing\nNow that we have our photo of Thai basil and Holy basil, Let’s see to get the sense of it.\n\nfrom fastai.vision.all import Image, get_image_files, verify_images\nfrom pathlib import Path\n\n\ndef remove_invalid_images(path, suffixes):\n    \"\"\"\n    Remove invalid images from in dataset folder.\n    \"\"\"\n    for suffix in suffixes:\n        filename = path/suffix\n        failed = verify_images(get_image_files(filename))\n        print(f\"In {filename}, There are {len(failed)} as unverified images: {failed}\")\n\n        if failed:\n            print(f\"Unlinking those files permanently...\")\n            failed.map(Path.unlink)\n\n\n# Horapa\nim = Image.open(\"gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa/20220425_221530.jpg\")\nim.to_thumb(256, 256)\n\n\n\n\n\n\n\n\nNote that the Image object has a height x width shape.\n\n# Kaprao\nim = Image.open(\"gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kaprao/20220425_205023(0).jpg\")\nim.to_thumb(256, 256)\n\n\n\n\n\n\n\n\nSee! those two types of ingredient are quite similar. I myself can not distinguish between them.\nNext, we will ensure the validity of our images before training.\n\npath = Path(\"gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data\")\nsuffixes = [\"horapa\", \"kaprao\"]\nremove_invalid_images(path, suffixes)\n\nIn gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa, There are 0 as unverified images: []\nIn gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/kaprao, There are 0 as unverified images: []\n\n\nGood! we can use all images we have downloaded for experimentation.",
    "crumbs": [
      "Projects",
      "Is it actually holy basil?"
    ]
  },
  {
    "objectID": "projects/horapa-vs-kaprao.html#training-fine-tuning",
    "href": "projects/horapa-vs-kaprao.html#training-fine-tuning",
    "title": "Is it actually holy basil?",
    "section": "Training (Fine-Tuning)",
    "text": "Training (Fine-Tuning)\nWe will use various sizes of resnet to explore how it performing against our dataset.\n\nHigh-level APIs\nfastai offer multiple levels of APIs. This is very useful when learning to use library to do deep learning. At first, it abstracts everything for you and let you configure less parameters. Throughout the course, this code will be develop to be used lower APIs.\n\nfrom fastai.vision.all import Resize, resnet34, error_rate\nfrom fastai.vision.data import ImageDataLoaders, parent_label\nfrom fastai.vision.learner import vision_learner\n\n\ndls = ImageDataLoaders.from_folder(\n    path=path,\n    valid_pct=0.2,\n    seed=42,\n    item_tfms=[Resize(192, method=\"squish\")] # squeeze image together as opposed to cropping\n)\n\ndls.show_batch(max_n=6)\n\n\n\n\n\n\n\n\n\nlearn = vision_learner(dls, resnet34, metrics=error_rate)\nlearn.fine_tune(3)\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.665408\n0.259226\n0.081545\n05:02\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.136087\n0.102042\n0.017167\n04:48\n\n\n1\n0.080034\n0.055630\n0.017167\n04:54\n\n\n2\n0.049438\n0.054968\n0.008584\n04:45\n\n\n\n\n\n\n\n# Save it for later use\n!mkdir \"gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/model\"\nlearn.export(\"../model/horapa-vs-kaprao-resnet34.pkl\")\n\nFrom error_rate, we will see that it incorrectly classified less than 1%!\nThis model looks really good but does it? We need to introduce another set of data to ensure it.\nBefore going to the next section, I would like to note that despite the higher-level APIs, there are many configurations and hyperparameters that we can choose from:\n\nfrom_folder method in ImageDataLoaders object helps label data from the folder name.\nvalid_pct is a proportion of validation data used to evaluate the model across epoch.\nitem_tfms is the transformation on data in this case we set it to be Resize(192, method=\"squish\"). Therefore, every images will be 192x192 via squeezing.\n\nNext, we have configuration on the training process\n\nresnet34 is the starting architecture that we will use\nerror_rate is a metrics used to validate the model\nepoch is the number of epochs (a round trip of data to train the model). In this case, we train the model 3 round-trip of our data.\nlearning_rate is the step size of how fast you want the model to learn a particular batch of data.",
    "crumbs": [
      "Projects",
      "Is it actually holy basil?"
    ]
  },
  {
    "objectID": "projects/horapa-vs-kaprao.html#evaluation",
    "href": "projects/horapa-vs-kaprao.html#evaluation",
    "title": "Is it actually holy basil?",
    "section": "Evaluation",
    "text": "Evaluation\nNow, back to business, model performance is the first thing we care about when developing ML project. So, it is the best practice that we test out our model using unseen data called Validation dataset. As you probably know, you have already tested the model!\nRemember the result table we saw when training, valid_loss is the model performance from held-out dataset splitted by valid_pct. If it decrease over epochs, we can ensure the model can generalize to some extent but we are not done.\nIn practice, we need to do an experiment several times by training the model with different hyperparameters or even dealing with data processing in order to tap the highest potential of the model. It is a trial-and-error process.\nTherefore, at the end of the day, we might bias ourselves from the choices that you have made. As a result, it is a best practice to have another held-out dataset to ensure the model performance before going into production.\n\nTest Set\nWe will use duckduckgo-search to find a set of images online to be used as test set.\n\nimport time\nfrom duckduckgo_search import DDGS\nfrom fastcore.all import L\nfrom fastai.vision.all import download_images, resize_images\n\n\ndef fetch_images(path, searches):\n    \"\"\"\n    Fetch images from the given search keywords.\n    \"\"\"\n    for s in searches:\n        dest = path/searches[s]\n        dest.mkdir(exist_ok=True, parents=True)\n\n        download_images(dest, urls=search_images(f\"{s} photo\"))\n        resize_images(dest, dest=dest, max_size=256)\n\n        # Pause between search to avoid over-loading server\n        time.sleep(10)\n\n\ndef search_images(term, max_images=30):\n    \"\"\"\n    Get image urls from the given term.\n    \"\"\"\n    with DDGS() as ddgs:\n        ddgs_images_gen = ddgs.images(\n            term,\n            max_results=max_images\n        )\n\n        print(f\"Searching for '{term}' ...\")\n        urls = L(ddgs_images_gen).itemgot(\"image\")\n\n    return urls\n\n\nsearches = {\"thai basil\": \"horapa\", \"holy basil\": \"kaprao\"}\npath = Path(\"gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa_or_kaprao\")\n\nfetch_images(path, searches)\n\nSearching for 'thai basil photo' ...\nSearching for 'holy basil photo' ...\n\n\nLike training set, we need to make sure that we only have valid images for testing.\n\nsuffixes = [searches[s] for s in searches]\nremove_invalid_images(path, suffixes)\n\nIn gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa_or_kaprao/horapa, There are 1 as unverified images: [Path('gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa_or_kaprao/horapa/db37cc19-b8a5-4b48-81ed-ddd5abb9fcfb.jpg')]\nUnlinking those files permanently...\nIn gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa_or_kaprao/kaprao, There are 2 as unverified images: [Path('gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa_or_kaprao/kaprao/5ea6388c-72a5-4297-be3f-b54526a2f7d6.jpg'), Path('gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa_or_kaprao/kaprao/d0ea452a-ed4e-4f1f-833f-517644a20049.jpg')]\nUnlinking those files permanently...\n\n\n\n\nPrediction\nNow that we have a test set, let’s make a batch prediction to see if our model can really do a good job.\n\nfrom fastai.vision.all import PILImage\nfrom sklearn.metrics import classification_report\n\n\ndef prediction(path, print_logs=False, n_logs=5):\n    \"\"\"\n    Make a prediction.\n    \"\"\"\n    folders = path.ls()\n    y_true = list()\n    y_pred = list()\n\n    for f in folders:\n        label = f.stem\n        image_files = get_image_files(f)\n\n        true_idx = 0 if label == \"horapa\" else 1\n\n        for i, image_file in enumerate(image_files):\n            # Load an image as Pillow Image (TensorImage) for making a prediction\n            img = PILImage.create(image_file)\n            is_horapa, pred_idx, probs = learn.predict(img)\n\n            if i &lt; n_logs and print_logs:\n                print(f\"I'm {probs[pred_idx]:.2%} sure this is {is_horapa}. Actually it is {label}!\")\n                print(f\"Filename: {image_file}\")\n                print(\"*\" * 100)\n\n            i += 1\n            y_true.append(true_idx)\n            y_pred.append(pred_idx.item())\n\n    return y_true, y_pred\n\nLet’s see a glimpse of our predictions.\n\npath = Path(\"gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa_or_kaprao\")\ny_true, y_pred = prediction(path, print_logs=True)\n\n\n\n\n\n\n\n\nI'm 100.00% sure this is horapa. Actually it is horapa!\nFilename: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa_or_kaprao/horapa/caa46603-b6ce-44d0-86ab-e7f747595f20.jpeg\n****************************************************************************************************\nI'm 99.93% sure this is horapa. Actually it is horapa!\nFilename: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa_or_kaprao/horapa/38e6829b-417c-4cbf-bd44-0b747d70dc35.jpg\n****************************************************************************************************\nI'm 99.99% sure this is horapa. Actually it is horapa!\nFilename: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa_or_kaprao/horapa/533be2d3-d7ac-49fc-910a-b1368d6abdf6.jpg\n****************************************************************************************************\nI'm 92.83% sure this is horapa. Actually it is horapa!\nFilename: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa_or_kaprao/horapa/185dc0ab-7fcb-4129-a0b6-b048b42274fb.jpg\n****************************************************************************************************\nI'm 100.00% sure this is horapa. Actually it is horapa!\nFilename: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa_or_kaprao/horapa/9a4ff1c0-fde4-4967-b60d-b7310c63051a.jpg\n****************************************************************************************************\nI'm 100.00% sure this is kaprao. Actually it is kaprao!\nFilename: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa_or_kaprao/kaprao/60584e49-0197-4fa1-96c5-8965be369762.jpg\n****************************************************************************************************\nI'm 100.00% sure this is kaprao. Actually it is kaprao!\nFilename: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa_or_kaprao/kaprao/bdfcec70-a5f7-4a75-8e1d-16309d20e837.jpg\n****************************************************************************************************\nI'm 99.99% sure this is kaprao. Actually it is kaprao!\nFilename: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa_or_kaprao/kaprao/c2614921-f431-49be-896b-da0132add88b.jpg\n****************************************************************************************************\nI'm 99.87% sure this is kaprao. Actually it is kaprao!\nFilename: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa_or_kaprao/kaprao/b9b4d37d-7550-4d34-bdb8-eecb469d97cd.jpg\n****************************************************************************************************\nI'm 97.84% sure this is kaprao. Actually it is kaprao!\nFilename: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa_or_kaprao/kaprao/4e6e309f-b298-43a7-bf71-f714b0bcd8cd.jpg\n****************************************************************************************************\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# F1-score for positive class\nprint(classification_report(y_true, y_pred))\n\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        27\n           1       1.00      1.00      1.00        27\n\n    accuracy                           1.00        54\n   macro avg       1.00      1.00      1.00        54\nweighted avg       1.00      1.00      1.00        54\n\n\n\nWow! resnet34 is correctly classified all images we fed to it.",
    "crumbs": [
      "Projects",
      "Is it actually holy basil?"
    ]
  },
  {
    "objectID": "projects/horapa-vs-kaprao.html#bigger-architecuture-with-lower-level-apis",
    "href": "projects/horapa-vs-kaprao.html#bigger-architecuture-with-lower-level-apis",
    "title": "Is it actually holy basil?",
    "section": "Bigger Architecuture with Lower-level APIs",
    "text": "Bigger Architecuture with Lower-level APIs\nLet’s try something even more fun! What happens if we use a bigger model, since we’ve already get 100% F1-score, the model should not perform worse than that Right?\nWell, it is not necessary the case. Let’s see how the bigger model will perform over our test set.\n\nfrom fastai.vision.all import resnet50\nfrom fastai.vision.data import DataBlock, ImageBlock, CategoryBlock, RandomSplitter\n\n\npath = Path(\"gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data\")\n\ndls = DataBlock(\n    blocks=(ImageBlock, CategoryBlock),\n    get_items=get_image_files,\n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=[Resize(192, method=\"squish\")]\n).dataloaders(path)\n\ndls.show_batch(max_n=6)\n\n\n\n\n\n\n\n\nIn fastai, we can use even more lower-level APIs. DataBlock object is one this example. As you can see, it is also required ImageBlock and CategoryBlock as to input and output modification. We can also identify how we want to split data but in this case, we still do RandomSplitter as it is ok to do so with this dataset.\nNote that we do not use from_folder method anymore. Instead, we use parent_label to label from their parent name which in this case, a folder name.\n\nlearn = vision_learner(dls, resnet50, metrics=error_rate)\nlearn.fine_tune(3)\n\nDownloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n100%|██████████| 97.8M/97.8M [00:01&lt;00:00, 94.7MB/s]\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.587313\n0.078603\n0.021459\n05:12\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.085145\n0.083044\n0.025751\n05:50\n\n\n1\n0.052234\n0.181116\n0.034335\n05:24\n\n\n2\n0.038099\n0.099724\n0.030043\n05:45\n\n\n\n\n\n\nOff to a bad start. It seems like valid_loss and error_rate flactuate a lot across each epoch. Well, it might suggest that the bigger model in this case perform worse. But to ensure we also need to check with our test set.\n\npath = Path(\"gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa_or_kaprao\")\ny_true, y_pred = prediction(path, print_logs=True)\n\n\n\n\n\n\n\n\nI'm 99.97% sure this is horapa. Actually it is horapa!\nFilename: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa_or_kaprao/horapa/caa46603-b6ce-44d0-86ab-e7f747595f20.jpeg\n****************************************************************************************************\nI'm 99.54% sure this is horapa. Actually it is horapa!\nFilename: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa_or_kaprao/horapa/38e6829b-417c-4cbf-bd44-0b747d70dc35.jpg\n****************************************************************************************************\nI'm 99.99% sure this is horapa. Actually it is horapa!\nFilename: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa_or_kaprao/horapa/533be2d3-d7ac-49fc-910a-b1368d6abdf6.jpg\n****************************************************************************************************\nI'm 87.44% sure this is horapa. Actually it is horapa!\nFilename: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa_or_kaprao/horapa/185dc0ab-7fcb-4129-a0b6-b048b42274fb.jpg\n****************************************************************************************************\nI'm 99.99% sure this is horapa. Actually it is horapa!\nFilename: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa_or_kaprao/horapa/9a4ff1c0-fde4-4967-b60d-b7310c63051a.jpg\n****************************************************************************************************\nI'm 100.00% sure this is kaprao. Actually it is kaprao!\nFilename: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa_or_kaprao/kaprao/60584e49-0197-4fa1-96c5-8965be369762.jpg\n****************************************************************************************************\nI'm 100.00% sure this is kaprao. Actually it is kaprao!\nFilename: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa_or_kaprao/kaprao/bdfcec70-a5f7-4a75-8e1d-16309d20e837.jpg\n****************************************************************************************************\nI'm 100.00% sure this is kaprao. Actually it is kaprao!\nFilename: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa_or_kaprao/kaprao/c2614921-f431-49be-896b-da0132add88b.jpg\n****************************************************************************************************\nI'm 99.98% sure this is kaprao. Actually it is kaprao!\nFilename: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa_or_kaprao/kaprao/b9b4d37d-7550-4d34-bdb8-eecb469d97cd.jpg\n****************************************************************************************************\nI'm 99.64% sure this is kaprao. Actually it is kaprao!\nFilename: gdrive/My Drive/practical-deep-learning/horapa-vs-kaprao/data/horapa_or_kaprao/kaprao/4e6e309f-b298-43a7-bf71-f714b0bcd8cd.jpg\n****************************************************************************************************\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# F1-score for positive class\nprint(classification_report(y_true, y_pred))\n\n              precision    recall  f1-score   support\n\n           0       0.86      0.89      0.87        27\n           1       0.88      0.85      0.87        27\n\n    accuracy                           0.87        54\n   macro avg       0.87      0.87      0.87        54\nweighted avg       0.87      0.87      0.87        54\n\n\n\nresnet50 gives us 87% of F1-score and as you can see, it worse than resnet34 as it is likely to suffer from overfitting due to its bigger architecture.\n\n# Save it for later use\nlearn.export(\"../model/horapa-vs-kaprao-resnet50.pkl\")",
    "crumbs": [
      "Projects",
      "Is it actually holy basil?"
    ]
  }
]